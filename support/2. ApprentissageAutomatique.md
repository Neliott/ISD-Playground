# THÉORIE DE L'APPRENTISSAGE AUTOMATIQUE (MACHINE LEARNING)

## 1. Fondamentaux et Paradigmes

### Définition et Vision "Software 2.0"
[cite_start]L'apprentissage automatique (Machine Learning - ML) est un sous-domaine de l'IA qui utilise des approches mathématiques et statistiques pour permettre aux ordinateurs d'améliorer leurs performances sur une tâche donnée à partir de données, sans être explicitement programmés pour chaque cas[cite: 3811].
[cite_start]C'est un changement de paradigme (**Software 2.0**) : au lieu de coder des règles (Software 1.0), on fournit des données et les sorties attendues, et l'algorithme génère le programme (le modèle)[cite: 3914].

### Les Paradigmes d'Apprentissage
Il existe plusieurs types d'apprentissage selon la nature des données disponibles :
* **Apprentissage Supervisé :** Le système apprend à partir d'exemples étiquetés (paires entrée/sortie désirée). [cite_start]Objectif : apprendre une fonction capable de prédire la sortie pour de nouvelles entrées[cite: 3872, 3881].
* **Apprentissage Non Supervisé :** Les données ne sont pas étiquetées. [cite_start]Objectif : découvrir la structure sous-jacente ou des groupes (clustering)[cite: 3876, 3948].
* [cite_start]**Apprentissage par Renforcement :** Apprentissage par essai-erreur basé sur un système de récompenses/punitions suite à des actions[cite: 3878, 3960].

---

## 2. Apprentissage Supervisé : Classification

[cite_start]La classification consiste à prédire une étiquette (classe discrète) pour une donnée d'entrée[cite: 475, 3984].

### A. Algorithme des k Plus Proches Voisins (k-NN)
[cite_start]C'est une méthode d'**apprentissage paresseux** (Lazy Learning) car il n'y a pas de construction de modèle explicite pendant l'entraînement ; toute la base de données est utilisée lors de la prédiction [cite: 638-640].

* [cite_start]**Principe :** Une nouvelle observation est classée selon le vote majoritaire de ses $k$ voisins les plus proches dans l'espace des caractéristiques[cite: 579].
* [cite_start]**Métrique :** La similarité est souvent mesurée par la **distance Euclidienne** ($L2$) ou la distance de Manhattan ($L1$) [cite: 605, 859-860].
* **Hyperparamètre $k$ :**
    * $k$ petit : Capte bien l'information locale mais sensible au bruit (risque d'overfitting). [cite_start]Frontières de décision complexes [cite: 670-672].
    * [cite_start]$k$ grand : Lisse les frontières de décision, réduit l'impact du bruit, mais peut perdre des détails et augmente le coût de calcul [cite: 660-662, 679].
* [cite_start]**Extension (Weighted k-NN) :** Pondérer le vote des voisins par l'inverse de leur distance pour donner plus d'importance aux points très proches[cite: 837, 853].

### B. Learning Vector Quantization (LVQ)
[cite_start]C'est une méthode d'**apprentissage en ligne** (Online Learning) qui construit un modèle explicite basé sur des **prototypes** (codebooks)[cite: 888, 907].

* **Principe :** On cherche un ensemble réduit de vecteurs prototypes qui représentent les classes de la base de données. [cite_start]Cela permet une compression de l'information et une prédiction plus rapide que k-NN[cite: 890, 899].
* **Algorithme d'entraînement :**
    1.  Initialiser des prototypes.
    2.  Pour chaque donnée d'entraînement, trouver le prototype le plus proche (Best Matching Unit - BMU).
    3.  **Mise à jour :**
        * Si la classe du prototype correspond à celle de la donnée : **Rapprocher** le prototype.
        * [cite_start]Si la classe diffère : **Éloigner** le prototype [cite: 968, 1049-1050].
* [cite_start]**Hyperparamètres :** Nombre de prototypes, taux d'apprentissage (*learning rate*), nombre d'itérations (*epochs*)[cite: 1150].

---

## 3. Apprentissage Supervisé : Régression Linéaire

[cite_start]La régression cherche à prédire une **variable continue** (et non une classe) en fonction de variables explicatives[cite: 1184].

### Le Modèle Linéaire
* [cite_start]**Régression Simple :** Relation entre une variable dépendante $y$ et une variable indépendante $x$ sous la forme d'une droite : $\hat{y} = mx + b$ (où $m$ est la pente et $b$ l'ordonnée à l'origine)[cite: 1253, 1465].
* [cite_start]**Régression Multiple :** Extension à plusieurs variables explicatives : $y = a x_1 + b x_2 + ... + k$[cite: 1275].

### Entraînement et Optimisation
L'objectif est de trouver les paramètres ($m, b$) qui minimisent l'erreur entre la prédiction $\hat{y}$ et la réalité $y$.

1.  **Fonction de Coût (Loss) :** On utilise généralement l'Erreur Quadratique Moyenne (**MSE** - Mean Squared Error) :
    [cite_start]$$MSE = \frac{1}{N}\sum_{i=1}^{N}(y_i - \hat{y}_i)^2$$[cite: 1522].
2.  **Méthode de la Descente de Gradient :** Algorithme itératif pour minimiser la fonction de coût.
    * On calcule la **dérivée** (le gradient) de l'erreur par rapport aux paramètres.
    * [cite_start]On met à jour les paramètres dans la direction opposée au gradient pour descendre vers le minimum de l'erreur[cite: 1639, 1673].
    * **Learning Rate (taux d'apprentissage) :** Contrôle la vitesse de la descente. [cite_start]Trop petit = lent ; trop grand = risque de divergence[cite: 1692].
3.  **Variantes :**
    * [cite_start]*Stochastique :* Mise à jour après chaque exemple (rapide, bruité)[cite: 1787].
    * [cite_start]*Batch :* Mise à jour après un lot d'exemples (compromis)[cite: 1810].

---

## 4. Méthodologie et Évaluation des Modèles

### Généralisation et Biais
[cite_start]Le but ultime est la **généralisation** : le modèle doit être performant sur des données qu'il n'a jamais vues[cite: 2941].
* [cite_start]**Underfitting (Sous-apprentissage) :** Modèle trop simple, ne capture pas la structure des données[cite: 2950].
* [cite_start]**Overfitting (Sur-apprentissage) :** Modèle trop complexe, apprend le bruit ou "par cœur" les données d'entraînement, ne généralise pas[cite: 2948].

### Protocoles de Validation
[cite_start]Pour évaluer honnêtement un modèle, on ne doit jamais le tester sur les données utilisées pour l'entraînement[cite: 699].
1.  [cite_start]**Hold-out :** Division simple (ex: 60% train, 40% test)[cite: 2970].
2.  **Validation Croisée (Cross-validation) :** Division en $k$ plis (*folds*). On entraîne sur $k-1$ plis et on teste sur le dernier. On répète l'opération $k$ fois et on moyenne les résultats. [cite_start]Plus robuste[cite: 3030].
3.  [cite_start]**Sélection de modèle :** Utilisation d'un ensemble de *validation* (distinct du *test set*) pour régler les hyperparamètres[cite: 3047].

### Mesures de Performance (Classification)
[cite_start]L'**Accuracy** (taux de réussite global) est souvent insuffisante, surtout si les classes sont déséquilibrées (ex: 95% de classe A, 5% de classe B)[cite: 3082]. On utilise la **Matrice de Confusion** :
* **Vrais Positifs (TP) / Vrais Négatifs (TN)** : Prédictions correctes.
* **Faux Positifs (FP)** : Alarme fausse (type I).
* [cite_start]**Faux Négatifs (FN)** : Détection manquée (type II)[cite: 3092].

Métriques dérivées :
* [cite_start]**Précision :** $TP / (TP + FP)$ (Fiabilité des prédictions positives)[cite: 3202].
* [cite_start]**Rappel (Recall/Sensibilité) :** $TP / (TP + FN)$ (Capacité à trouver tous les positifs)[cite: 3203].
* [cite_start]**F-Score :** Moyenne harmonique entre précision et rappel[cite: 3241].

### Mesures de Performance (Régression)
* **Coefficient de détermination ($R^2$) :** Mesure la proportion de la variance de la variable dépendante expliquée par le modèle. $R^2 = 1$ est un modèle parfait ; [cite_start]$R^2 = 0$ équivaut à prédire la moyenne simple[cite: 1904, 1910].