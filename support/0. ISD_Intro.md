## 1. Organisation et Déroulement du Cours

### Plateformes et Communication
* [cite_start]**Moodle :** 2025-26-HEIG-VD-ISD-CD [cite: 6]
* [cite_start]**Teams (Laboratoires) :** ISD-CD-2025-26 [cite: 6]
* [cite_start]**Clé d'inscription :** 2526-ISD-CD-SRT [cite: 8]
* [cite_start]**Communication :** Par Emails [cite: 9]

### Évaluation
[cite_start]La note finale est calculée selon la pondération suivante[cite: 16]:
* [cite_start]**30% :** Moyenne des travaux écrits (contrôle continu)[cite: 16]. [cite_start]Il y aura au moins 2 tests d'une durée totale d'au moins 2 périodes[cite: 13].
* [cite_start]**20% :** Moyenne laboratoire (basée sur les rapports de manipulation, minimum 3 reprises)[cite: 14, 16].
* [cite_start]**50% :** Examen final (écrit commun, durée de 90 minutes)[cite: 15, 16].

### Objectifs Pédagogiques
[cite_start]À la fin du cours, les étudiants sauront : **préparer des données, entraîner un modèle simple et évaluer sa performance**[cite: 17].
[cite_start]Le cours couvre les outils, le Machine Learning, le calcul scientifique, l'apprentissage supervisé et non supervisé, la régression linéaire et l'évaluation des performances[cite: 21].

---

## 2. Qu'est-ce que la Science des Données ?

### Définition
[cite_start]La science des données est un domaine interdisciplinaire qui vise à extraire des connaissances à partir de données souvent volumineuses, complexes et hétérogènes[cite: 312, 586]. [cite_start]Elle repose sur l'intersection de trois grands domaines[cite: 337, 351, 353]:
1.  **Mathématiques et Statistiques**
2.  **Informatique (Programmation, Développement logiciel)**
3.  **Connaissance du métier/domaine (Business/Recherche classique)**

[cite_start]C'est une science qui emploie la **méthode scientifique**[cite: 405].

### Le Déluge de Données (Big Data)
[cite_start]Nous vivons une explosion de la quantité de données générées (trafic IP, tweets, recherches Google, objets connectés) [cite: 517-521].
* [cite_start]Le trafic IP annuel a dépassé plusieurs zettabytes[cite: 533].
* [cite_start]Ce déluge a propulsé la science des données, le Machine Learning et l'IA sous les feux des projecteurs [cite: 577-582].

### Rôles Clés : Data Scientist vs Data Engineer
* **Data Engineer :** Son but est de rendre les données **utilisables**. Il considère les données comme quelque chose à traiter, stocker et mettre à disposition efficacement. [cite_start]Il gère l'infrastructure et le nettoyage ("Superman" qui retient le train de données brutes)[cite: 639, 646, 648].
* **Data Scientist :** Son but est de rendre les données **utiles**. Il analyse les données brutes pour raconter une histoire, extraire des motifs (patterns) et créer de la valeur. [cite_start]Il est souvent décrit comme quelqu'un de meilleur en statistiques qu'un ingénieur logiciel, et meilleur en génie logiciel qu'un statisticien[cite: 620, 640, 648].

### Tâches Principales
[cite_start]Le flux de travail typique inclut : Collecte $\rightarrow$ Stockage $\rightarrow$ Traitement $\rightarrow$ Analyse/Inférence $\rightarrow$ Modélisation $\rightarrow$ Visualisation [cite: 626-635].

---

## 3. Intelligence Artificielle et Apprentissage Automatique

### Définitions
* [cite_start]**Intelligence Artificielle (IA) :** Discipline permettant aux machines d'imiter certaines capacités humaines (apprendre, reconnaître, décider)[cite: 77].
* **Apprentissage Automatique (Machine Learning - ML) :** Sous-domaine de l'IA. [cite_start]Au lieu de programmer explicitement des règles fixes, on entraîne l'ordinateur à réaliser une tâche à partir d'exemples[cite: 657, 686].

### Changement de Paradigme : Software 1.0 vs 2.0
* [cite_start]**Approche classique (Règles) :** Pour reconnaître une pomme rouge, on codait des règles strictes (si couleur = rouge et diamètre > 4cm...)[cite: 672]. C'est limité et rigide.
* **Approche ML (Software 2.0) :** On fournit des exemples (images de pommes) à un algorithme qui apprend les motifs lui-même. [cite_start]C'est la "fin du code" tel qu'on le connaît classiquement[cite: 686, 689]. [cite_start]Comme le dit Andrej Karpathy, le "Software 2.0" prend de plus en plus de place sur le "Software 1.0"[cite: 734].

### Méthodologie
Le processus suit la méthode scientifique :
1.  **Observation** (Données)
2.  **Théorie/Hypothèse** (Modèle)
3.  **Prédiction**
4.  **Expérience/Test**
5.  [cite_start]**Modification de la théorie** si nécessaire (Ajustement du modèle) [cite: 409-421, 693-700].

---

## 4. Exemples d'Application et Projets de Recherche

### Applications Générales de l'IA
[cite_start]L'IA est omniprésente : assistants vocaux (Siri), moteurs de recherche, filtres anti-spam, recommandations (Netflix/Spotify), détection de fraude, et même dans des domaines moins visibles comme l'optimisation logistique (robots Amazon) [cite: 754-764].

### IA Générative (GenAI)
Le cours aborde l'évolution rapide de la génération de contenu :
* [cite_start]**Image :** De résultats basiques en 2021 à du photoréalisme en 2023 (DALL-E, Stable Diffusion) [cite: 26-64].
* [cite_start]**Vidéo :** L'arrivée de technologies comme Sora (OpenAI) permettant de générer des vidéos photoréalistes à partir de texte[cite: 66].

### Projets de Recherche Appliquée (Présentés par les Professeurs)
Plusieurs projets concrets illustrent l'utilisation de la science des données :

1.  **GESICA (Gestion de crises sanitaires) :** Système intelligent pour détecter les signaux faibles de crises (épidémies, etc.) et optimiser les moyens hospitaliers. [cite_start]Partenariat avec HUG, CHUV, etc. [cite: 196-200].
2.  [cite_start]**SIA-REMU (Régulation Médicale des Urgences) :** Logiciel d'aide à la décision pour les centres 144 (ambulances, hélicoptères) afin d'optimiser l'engagement des moyens selon le trafic, la météo et la disponibilité hospitalière [cite: 213-215].
3.  [cite_start]**Prédiction de Séries Temporelles (avec Predictive Layer) :** Tuning adaptatif de réseaux de neurones pour le trading d'énergie et de commodités [cite: 220-224].
4.  [cite_start]**ALEA (Détection de Fraude Bancaire) :** Projet avec NetGuardians utilisant l'apprentissage actif et les auto-encodeurs pour détecter de nouveaux types de fraudes bancaires et réduire les faux positifs [cite: 229-240].
5.  [cite_start]**OPERATE (Optimisation des Blocs Opératoires) :** Utilisation du *Deep Reinforcement Learning* avec l'entreprise Calyps pour planifier et optimiser l'usage des salles d'opération face aux incertitudes [cite: 241-249].

---

## 5. Éthique et Risques

[cite_start]Le cours souligne que le vrai danger actuel de l'IA n'est pas "Terminator", mais la manipulation et la surveillance[cite: 773].

* [cite_start]**Cas Cambridge Analytica :** Utilisation de tests de personnalité (modèle OCEAN) et de données Facebook pour profiler psychologiquement des millions d'électeurs et cibler des publicités politiques (campagne Trump 2016) [cite: 775-786].
* **Biais et Risques :** Les systèmes prennent des décisions qui peuvent discriminer ou manipuler pour maximiser le profit.

[cite_start]Cependant, il existe aussi l'**"AI for Good"** : détection de la déforestation, développement de médicaments, cartographie de la pauvreté, etc. [cite: 828-834].

---

## 6. Outils Techniques du Cours

[cite_start]Le cours s'appuiera principalement sur l'écosystème **Python** pour la science des données [cite: 309, 870-883] :
* **Jupyter / IPython**
* **NumPy** (Calcul numérique)
* **Pandas** (Manipulation de données)
* **Matplotlib** (Visualisation)
* **Scikit-Learn** (Apprentissage automatique)